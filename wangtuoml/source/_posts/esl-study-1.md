---
title: 重温统计学习基础-2
author: 王椭
toc: true
date: 2017-07-11 22:01:35
tags: 
- esl
- base
- theory
categories: ml
description: 之前虽然看过统计学习基础，但是感觉看得并不仔细，后面的习题也没做过（感觉还是有点难度值得一做的），再加上实习了半年，虽然多了些实践的机会，但是也少了很多沉下心来学习的时间，因此打算每天晚上静下心来，重新看看*The Elements of Statistical Learning*,把里面的习题也做做。在有了半年多实践经验之后，再来回头看这书，应该也会有更多的收获了。

---


## Linear Methods for Regression

### 随手记
#### 开篇
在样本较少的情况下，线性模型是非常好的选择，大学的时候一直很瞧不起线性模型，但实际上，只要合理的选择、构造特征，再针对问题的特点对模型做出相应的修正，线性模型也能适用于非常多的问题，并且线性模型还能提供清晰直白的对自变量因变量之间关系的描述，感觉在遇到一个新问题时不妨先用线性模型试一试。此外，第五章还介绍了基函数方法（basis-function methods）,可以进一步拓展线性模型的应用范围。

#### 最小二乘

1.实质是为假定线性模型情况下的平方损失函数最小；2.几何解释：求输出向量在输入向量构成的超平面上的正交投影（因为是正交投影所以超平面上该投影与输出向量间的距离最短），即求得与输出向量最接近的输入向量的线性组合；3.对模型假设添加随机扰动项，在假定了随机扰动项的分布的情况下，可以对系数、对残差的估计的可靠性及可能的范围有相应的估计（置信度，置信区间），但这种估计必须在对随机扰动项的分布的假定是成立的情况下才有效。

#### 最优子集选择
特征选择问题。特征不是越多越好，可能会存在多重共线性，导致方差增大，估计不稳定，个人感觉如果加入了过多的特征，可能某些实际上与自变量无关的特征也混进来，并且由于随机性的关系，还表现出与自变量之间的弱相关性，进而产生过拟合。此外也影响模型的可解释性。因此需要对特征进行筛选。

最优子集选择的方法是离散的形式，特征要么被保留，要么被舍弃，但是也有另外一种思路shrinkage methods,通过收缩系数来实现。